# Tweet Categorization to Notion - Technical Specification

## Project Overview

**Project Name:** Tweet Categorization to Notion  
**Version:** 1.0  
**Last Updated:** December 30, 2025  
**Author:** Zamil

### Purpose
Automate the process of organizing and cataloging tweets related to nano banana pro prompts by extracting content, using AI to categorize and tag, extracting actual prompts, and storing structured data in a Notion database for easy retrieval and reference.

### Problem Statement
Manually reviewing, categorizing, and organizing tweet links is time-consuming and inconsistent. There's a need for an automated system that can:
- Extract tweet content from URLs
- Intelligently categorize tweets by type
- Extract actual nano banana pro prompts from tweet content
- Apply relevant tags
- Generate concise descriptions
- Store everything in a searchable database

### Solution
An n8n workflow that monitors a Notion database, processes pending tweet links, uses Claude AI for intelligent analysis and prompt extraction, and updates the database with structured, searchable information.

---

## System Architecture

### High-Level Architecture

```
┌─────────────────┐
│  Notion DB      │ (Source & Destination)
│  (Tweet Links)  │
└────────┬────────┘
         │
         │ Polling (every minute)
         ▼
┌─────────────────┐
│  n8n Workflow   │
│  Orchestrator   │
└────────┬────────┘
         │
         ├──────► vxtwitter API (Tweet Extraction)
         │
         ├──────► Claude API (AI Analysis)
         │
         └──────► Notion API (Database Update)
```

### Technology Stack

| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| Workflow Orchestration | n8n | Latest | Automation engine |
| Database | Notion | API v1 | Data storage & UI |
| AI Analysis | Claude | Haiku 4.5 | Categorization & extraction |
| Tweet Fetching | vxtwitter | API | Content retrieval |
| Runtime | Node.js | 18+ | Execution environment |

---

## Data Model

### Notion Database Schema

| Field Name | Type | Required | Description | Example Values |
|------------|------|----------|-------------|----------------|
| Name | Title | Yes | Tweet identifier/title | "Prompt engineering tip by @user" |
| URL | URL | Yes | Original tweet link | https://twitter.com/user/status/123 |
| Category | Select | No | Main classification | Technique, Use Case, Tips, Examples |
| Tags | Multi-select | No | Descriptive keywords | [prompt-engineering, advanced] |
| Description | Text | No | AI-generated summary | "Tweet discusses nested prompts..." |
| Prompt | Text | No | Extracted prompt text | "Act as a senior developer..." |
| Tweet Content | Text | No | Full tweet text | Original tweet body |
| Author | Text | No | Tweet author username | @username |
| Processing Status | Select | Yes | Workflow state | Pending, Processed, Error |
| Date Processed | Date | No | Processing timestamp | 2025-12-30T10:00:00Z |
| Date Added | Created time | Auto | Entry creation date | Auto-filled by Notion |

### Category Taxonomy

**Predefined Categories:**
1. **Technique** - Methods and approaches for using nano banana pro prompts
2. **Use Case** - Practical applications and real-world scenarios
3. **Tips** - Best practices and recommendations
4. **Examples** - Sample prompts and demonstrations
5. **Tutorial** - Step-by-step guides and instructions
6. **Inspiration** - Creative ideas and thought-provoking content
7. **Discussion** - Conversations and debates about prompting
8. **Uncategorized** - Fallback for unclear content

### Tag Structure

**Tag Categories:**
- **Skill Level:** beginner-friendly, intermediate, advanced
- **Topic Area:** prompt-engineering, nano-banana, code-review, content-creation
- **Quality Indicators:** best-practices, needs-review, verified
- **Content Type:** tutorial, example, discussion, technique

Tags are dynamically generated by AI and will grow organically over time.

---

## Workflow Specification

### Node Breakdown

#### 1. Notion Trigger Node
**Type:** `n8n-nodes-base.notionTrigger`  
**Version:** 2

**Configuration:**
```json
{
  "pollTimes": "everyMinute",
  "event": "page",
  "filters": {
    "property": "Processing Status",
    "condition": "equals",
    "value": "Pending"
  }
}
```

**Purpose:** Monitors Notion database for new entries with "Pending" status  
**Trigger Frequency:** Every 60 seconds  
**Output:** Notion page object with all properties

**Error Handling:**
- Database not found → Stops workflow, logs error
- No pending items → Continues polling without processing
- API rate limit → Backs off automatically

---

#### 2. Fetch Tweet Content Node
**Type:** `n8n-nodes-base.httpRequest`  
**Version:** 4.1

**Configuration:**
```javascript
URL: https://api.vxtwitter.com/Twitter/status/{tweet_id}
Method: GET
Authentication: None
```

**Input:** Tweet URL from Notion  
**Output:** Tweet data object containing:
- `text` - Tweet content
- `user_name` - Author username
- `created_at` - Tweet timestamp
- `likes`, `retweets` - Engagement metrics

**Tweet ID Extraction:**
```javascript
{{ $json.properties.URL.url.split('/').pop() }}
```

**Error Handling:**
- Tweet not found (404) → Skip to error state
- API unavailable → Retry with exponential backoff
- Rate limited → Queue for later processing

**Alternative APIs:**
If vxtwitter fails, alternatives include:
1. Twitter/X Official API (requires auth)
2. Nitter instances
3. Apify Twitter scraper

---

#### 3. Claude Analysis Node
**Type:** `n8n-nodes-base.httpRequest`  
**Version:** 4.1

**Configuration:**
```json
{
  "url": "https://api.anthropic.com/v1/messages",
  "method": "POST",
  "authentication": "anthropicApi",
  "headers": {
    "anthropic-version": "2023-06-01"
  },
  "body": {
    "model": "claude-haiku-4-5-20251001",
    "max_tokens": 500,
    "temperature": 0.3
  }
}
```

**Model Selection Rationale:**
- **Claude Haiku 4.5:** Fast, cost-effective, excellent for structured tasks
- **Temperature 0.3:** Low for consistency, not zero to allow slight variation
- **Max Tokens 500:** Sufficient for JSON response with all fields

**Prompt Structure:**
```
Analyze this tweet about nano banana pro prompts and provide a structured response.

Tweet Author: {author}
Tweet Text: {text}
Tweet URL: {url}

Provide your response in this exact JSON format:
{
  "category": "<one of: Technique|Use Case|Tips|Examples|Tutorial|Inspiration|Discussion>",
  "tags": ["<tag1>", "<tag2>", "<tag3>"],
  "description": "<concise 1-2 sentence description>",
  "prompt": "<the actual nano banana pro prompt if present, otherwise empty string>",
  "author": "{author}"
}

IMPORTANT - Prompt Extraction:
- Look for the actual nano banana pro prompt in the tweet
- Prompts are often in quotes, code blocks, or clearly formatted
- Extract the complete prompt text exactly as written
- If the tweet discusses prompts but doesn't contain an actual prompt, leave empty
- If multiple prompts, extract the primary/main one

Focus on:
- What aspect of nano banana pro prompts this covers
- Key techniques or insights mentioned
- Practical application value

Respond ONLY with valid JSON, no other text.
```

**Expected Output Format:**
```json
{
  "category": "Examples",
  "tags": ["prompt-engineering", "code-review", "advanced"],
  "description": "Demonstrates a structured prompt for code review with specific focus areas",
  "prompt": "Act as a senior developer. Review this code for: 1) Security issues 2) Performance 3) Best practices",
  "author": "@username"
}
```

**Error Handling:**
- Invalid JSON response → Use fallback values
- API timeout → Retry once, then mark as error
- Rate limit → Queue for later
- Empty response → Mark as needs-review

**Cost Estimation:**
- Input tokens: ~400 per tweet
- Output tokens: ~150 per tweet
- Cost per tweet: ~$0.001-0.002
- Monthly estimate (3000 tweets): ~$3-6

---

#### 4. Parse Response Node
**Type:** `n8n-nodes-base.code`  
**Version:** 2

**Purpose:** Extract and validate Claude's JSON response, prepare data for Notion

**Code Logic:**
```javascript
// Extract Claude's response from API result
const claudeResponse = $input.item.json.content?.[0]?.text || "";

let analysis;
try {
  // Clean markdown code blocks if present
  const cleanJson = claudeResponse
    .replace(/```json\n?|```/g, '')
    .trim();
  
  // Parse JSON
  analysis = JSON.parse(cleanJson);
} catch (error) {
  // Fallback for parsing failures
  console.error("Parse error:", error);
  analysis = {
    category: "Uncategorized",
    tags: ["needs-review"],
    description: "Failed to parse analysis",
    prompt: "",
    author: $('Fetch Tweet Content').item.json.user_name || "Unknown"
  };
}

// Get original data from previous nodes
const tweetData = $('Fetch Tweet Content').item.json;
const notionData = $('Notion Trigger').item.json;

// Return structured data for Notion update
return {
  json: {
    pageId: notionData.id,
    category: analysis.category,
    tags: analysis.tags,
    description: analysis.description,
    prompt: analysis.prompt || "",
    tweetContent: tweetData.text || "",
    author: tweetData.user_name || analysis.author || "Unknown",
    tweetUrl: notionData.properties.URL.url
  }
};
```

**Validation Rules:**
- Category must be one of predefined values
- Tags must be an array (empty array if none)
- All text fields sanitized for Notion rich text format
- Prompt field can be empty string (valid state)

**Output Schema:**
```typescript
interface ParsedData {
  pageId: string;           // Notion page ID
  category: string;         // One of predefined categories
  tags: string[];          // Array of tag strings
  description: string;     // Summary text
  prompt: string;          // Extracted prompt or empty
  tweetContent: string;    // Full tweet text
  author: string;          // Username
  tweetUrl: string;        // Original URL
}
```

---

#### 5. Update Notion Node
**Type:** `n8n-nodes-base.notion`  
**Version:** 2

**Configuration:**
```json
{
  "resource": "databasePage",
  "operation": "update",
  "pageId": "={{ $json.pageId }}"
}
```

**Property Mappings:**

| Notion Field | Source | Type | Expression |
|--------------|--------|------|------------|
| Category | analysis.category | select | `={{ $json.category }}` |
| Tags | analysis.tags | multi-select | `={{ $json.tags }}` |
| Description | analysis.description | richText | `={{ $json.description }}` |
| Prompt | analysis.prompt | richText | `={{ $json.prompt }}` |
| Tweet Content | tweetData.text | richText | `={{ $json.tweetContent }}` |
| Author | tweetData.user_name | richText | `={{ $json.author }}` |
| Processing Status | Processed | select | `Processed` |
| Date Processed | Current timestamp | date | `={{ $now.toISO() }}` |

**Rich Text Formatting:**
Notion rich text format requires:
```json
{
  "richText": "text content here"
}
```

**Error Handling:**
- Field doesn't exist → Workflow fails, needs manual DB update
- Invalid select value → Notion API rejects, mark as error
- Permission denied → Check integration access
- Rate limit → Retry with backoff

---

## Execution Flow

### Happy Path

```
1. Notion Trigger detects new "Pending" item
   ↓
2. Extract tweet URL from Notion page properties
   ↓
3. Parse tweet ID from URL
   ↓
4. Fetch tweet content via vxtwitter API
   ↓ (returns tweet data)
5. Send tweet data to Claude API with analysis prompt
   ↓ (returns JSON analysis)
6. Parse JSON response, extract all fields
   ↓
7. Validate data structure
   ↓
8. Update Notion page with all extracted data
   ↓
9. Set status to "Processed", add timestamp
   ↓
✓ Complete (ready for next item)
```

**Execution Time:** ~3-5 seconds per tweet

### Error Scenarios

**Scenario 1: Tweet Not Found**
```
Fetch Tweet → 404 Error
→ Set Processing Status = "Error"
→ Set Description = "Tweet not found or deleted"
→ Stop processing
```

**Scenario 2: Claude API Failure**
```
Claude Analysis → Timeout/Error
→ Retry once after 2 seconds
→ If still fails: Use fallback category "Uncategorized"
→ Add tag "needs-review"
→ Continue to Notion update
```

**Scenario 3: JSON Parse Failure**
```
Parse Response → JSON.parse() throws error
→ Use fallback analysis object
→ Category: "Uncategorized"
→ Tags: ["needs-review"]
→ Description: "Failed to parse analysis"
→ Continue to Notion update
```

**Scenario 4: Notion Update Failure**
```
Update Notion → Permission denied
→ Log error with page ID
→ Do not retry (prevents infinite loop)
→ Notify user via n8n error workflow (optional)
```

---

## Prompt Extraction Logic

### Extraction Heuristics

Claude uses the following decision tree for prompt extraction:

```
Is tweet text wrapped in quotes? ──► Yes ──► Extract quoted text
   │
   No
   │
   ▼
Contains code block markers? ──► Yes ──► Extract code block content
   │
   No
   │
   ▼
Contains "prompt:" or similar? ──► Yes ──► Extract following text
   │
   No
   │
   ▼
Has clear instruction format? ──► Yes ──► Extract instruction
   │
   No
   │
   ▼
Return empty string (no extractable prompt)
```

### Extraction Patterns

**Pattern 1: Quoted Prompts**
```
Input: "Here's my prompt: 'Analyze this code for bugs'"
Output: "Analyze this code for bugs"
```

**Pattern 2: Code Blocks**
```
Input: "Try this:\n```\nYou are an expert...\n```"
Output: "You are an expert..."
```

**Pattern 3: Structured Format**
```
Input: "Role: Developer\nTask: Review code\nOutput: List of issues"
Output: "Role: Developer\nTask: Review code\nOutput: List of issues"
```

**Pattern 4: Multi-line Clear Format**
```
Input: "My nano banana prompt:\n\nGenerate a report with:\n- Summary\n- Key points"
Output: "Generate a report with:\n- Summary\n- Key points"
```

### Non-Extraction Cases

Claude will NOT extract in these cases:
- Questions about prompts ("What prompts do you use?")
- Meta-discussion ("Prompts are useful because...")
- Incomplete fragments ("Start your prompt with...")
- Vague references ("I use prompts for this")

These will result in empty `prompt` field.

---

## Configuration Requirements

### Environment Setup

**n8n Configuration:**
```yaml
# n8n environment variables (if self-hosted)
N8N_BASIC_AUTH_ACTIVE: true
N8N_BASIC_AUTH_USER: admin
N8N_BASIC_AUTH_PASSWORD: [secure_password]
WEBHOOK_URL: https://your-n8n-instance.com
EXECUTIONS_DATA_PRUNE: true
EXECUTIONS_DATA_MAX_AGE: 168  # 7 days
```

**Notion Integration Setup:**
1. Go to https://www.notion.so/my-integrations
2. Create new integration: "Tweet Categorization Bot"
3. Grant capabilities:
   - Read content
   - Update content
   - Insert content
4. Copy Internal Integration Token
5. Share target database with integration

**Anthropic API Setup:**
1. Get API key from https://console.anthropic.com/
2. No special configuration needed
3. Ensure billing is configured
4. Monitor usage dashboard

### Credential Storage

**n8n Credentials Format:**

**Notion API:**
```json
{
  "name": "Notion API - Tweet DB",
  "type": "notionApi",
  "data": {
    "apiKey": "secret_xxxxxxxxxxxx"
  }
}
```

**Anthropic API:**
```json
{
  "name": "Claude API - Haiku",
  "type": "anthropicApi",
  "data": {
    "apiKey": "sk-ant-xxxxxxxxxxxx"
  }
}
```

---

## Performance Specifications

### Processing Capacity

| Metric | Value | Notes |
|--------|-------|-------|
| Tweets per minute | 1 | Limited by polling frequency |
| Tweets per hour | 60 | Theoretical maximum |
| Tweets per day | 1,440 | Continuous operation |
| Concurrent processing | 1 | Sequential by design |
| Retry attempts | 1 | For Claude API only |
| Timeout per tweet | 30s | Total workflow timeout |

### Resource Requirements

**n8n Instance:**
- CPU: 1 vCPU minimum
- RAM: 512MB minimum
- Storage: 10GB (for logs and execution data)
- Network: Stable internet required

**API Rate Limits:**
- **vxtwitter:** No documented limit, generous
- **Claude API:** 
  - Haiku: 50 requests/minute (tier 1)
  - 40,000 tokens/minute
- **Notion API:**
  - 3 requests/second per integration

**Current bottleneck:** Polling frequency (1 minute)

### Scalability Considerations

**To increase throughput:**
1. Reduce polling interval to 30 seconds (2x capacity)
2. Process multiple pending items per execution (batch processing)
3. Use webhook trigger instead of polling (real-time)
4. Implement parallel processing for independent tweets

**Current design rationale:**
- Simple, reliable, easy to debug
- Adequate for personal use (< 100 tweets/day)
- Can be enhanced when needed

---

## Error Handling & Logging

### Error States

**Processing Status Values:**
1. **Pending** - Awaiting processing
2. **Processed** - Successfully completed
3. **Error** - Failed processing (requires manual review)

### Error Logging Strategy

**n8n Built-in Logging:**
- Execution history retained for 7 days
- Full input/output data for each node
- Error stack traces available
- Search and filter by status

**Custom Error Notifications (Optional Enhancement):**
```javascript
// Add notification node for errors
if (processingStatus === 'Error') {
  sendTelegramMessage({
    chat_id: TELEGRAM_CHAT_ID,
    text: `Tweet processing failed: ${tweetUrl}\nError: ${errorMessage}`
  });
}
```

### Monitoring Metrics

**Key Performance Indicators:**
1. Success rate (Processed / Total)
2. Average processing time per tweet
3. Claude API cost per day/month
4. Error rate by type
5. Queue backlog (pending items)

**Recommended Monitoring:**
- Daily summary of processed tweets
- Weekly cost report
- Error alerts for >5 failures per hour

---

## Security Considerations

### API Key Management

**Best Practices:**
1. Store API keys in n8n credentials (encrypted at rest)
2. Never commit credentials to version control
3. Rotate API keys quarterly
4. Use read-only keys where possible
5. Implement IP allowlisting if available

### Data Privacy

**Sensitive Data Handling:**
- Tweet content is public data (no PII concerns)
- Notion database should have appropriate sharing settings
- Claude API: Data is not used for training (per Anthropic policy)
- vxtwitter: Public API, no authentication required

**Access Control:**
- Notion integration: Limit to specific database only
- n8n workflow: Protect with authentication
- API keys: Separate keys per environment (dev/prod)

### Rate Limit Protection

**Implemented Safeguards:**
1. Polling interval prevents flooding
2. Sequential processing (no bursts)
3. Exponential backoff on retries
4. Circuit breaker pattern (after 5 consecutive failures, pause for 5 minutes)

---

## Testing Specification

### Unit Testing

**Test Cases:**

**1. Tweet ID Extraction**
```javascript
// Test input: "https://twitter.com/user/status/1234567890"
// Expected output: "1234567890"
assert(extractTweetId(url) === "1234567890");
```

**2. JSON Parsing with Markdown**
```javascript
// Test input: "```json\n{\"category\":\"Tips\"}\n```"
// Expected output: {category: "Tips"}
assert(parseClaudeResponse(input).category === "Tips");
```

**3. Fallback Handling**
```javascript
// Test input: Invalid JSON
// Expected output: Fallback object with "Uncategorized"
assert(parseClaudeResponse("invalid").category === "Uncategorized");
```

### Integration Testing

**Test Scenario 1: Full Happy Path**
```
1. Create test tweet link in Notion
2. Set Processing Status = "Pending"
3. Wait for workflow execution
4. Verify all fields populated
5. Verify status = "Processed"
```

**Test Scenario 2: Tweet with Prompt**
```
1. Use known tweet with clear prompt
2. Process through workflow
3. Verify prompt extracted correctly
4. Verify prompt field is not empty
```

**Test Scenario 3: Tweet without Prompt**
```
1. Use tweet discussing prompts (no actual prompt)
2. Process through workflow
3. Verify prompt field is empty string
4. Verify description still generated
```

**Test Scenario 4: Deleted Tweet**
```
1. Use invalid/deleted tweet URL
2. Process through workflow
3. Verify status = "Error"
4. Verify error message populated
```

### Load Testing

**Batch Processing Test:**
```
1. Add 50 pending tweets
2. Monitor processing over 50 minutes
3. Verify all processed successfully
4. Check for any timeouts or failures
5. Validate cost matches estimates
```

---

## Deployment Guide

### Initial Setup Checklist

- [ ] n8n instance running (cloud or self-hosted)
- [ ] Notion database created with all required fields
- [ ] Notion integration created and shared with database
- [ ] Anthropic API key obtained and tested
- [ ] n8n credentials configured (Notion + Anthropic)
- [ ] Workflow JSON imported to n8n
- [ ] Test tweet added with "Pending" status
- [ ] Workflow tested and verified working
- [ ] Workflow activated

### Deployment Steps

**Step 1: Database Preparation**
```sql
-- Create Notion database with schema from Data Model section
-- Configure select field options for Category
-- Configure multi-select field for Tags
-- Set Processing Status default to "Pending"
```

**Step 2: Integration Setup**
```bash
# Create Notion integration
# Copy integration token
# Share database with integration
```

**Step 3: n8n Configuration**
```bash
# Import workflow JSON
n8n import:workflow --input=tweet-categorization-workflow.json

# Add credentials
# - Notion API credential
# - Anthropic API credential

# Update Notion Trigger node with database ID
```

**Step 4: Validation**
```bash
# Execute workflow manually with test data
# Verify output in Notion database
# Check n8n execution logs
# Monitor for errors
```

**Step 5: Activation**
```bash
# Activate workflow in n8n
# Set polling to start
# Monitor first few executions
```

### Rollback Procedure

**If workflow fails after deployment:**
```bash
1. Deactivate workflow immediately
2. Set all "Error" items back to "Pending"
3. Review n8n execution logs for root cause
4. Fix configuration issue
5. Test manually before re-activating
```

---

## Maintenance & Operations

### Routine Maintenance

**Daily:**
- Monitor n8n dashboard for execution status
- Check for any tweets stuck in "Pending" state
- Review error rate (should be <5%)

**Weekly:**
- Review categorization quality (sample 10 random tweets)
- Check Claude API usage and costs
- Update tag options if new patterns emerge
- Clear old execution logs

**Monthly:**
- Rotate API keys (security best practice)
- Review and update category taxonomy if needed
- Analyze most common tags for optimization
- Audit Notion database for data quality

### Backup Strategy

**n8n Workflow:**
```bash
# Export workflow JSON monthly
n8n export:workflow --id=<workflow_id> --output=backup/

# Store in version control
git add tweet-workflow-backup-YYYY-MM-DD.json
git commit -m "Backup workflow configuration"
```

**Notion Database:**
```bash
# Notion has built-in version history (unlimited)
# Export CSV monthly for offline backup
# Store in secure cloud storage (Google Drive, Dropbox)
```

### Troubleshooting Guide

**Issue: Workflow not triggering**
```
Symptoms: No executions in n8n, tweets stuck in "Pending"
Diagnosis: 
  - Check workflow is activated
  - Verify Notion trigger node database ID
  - Check Notion credentials are valid
  - Confirm database is shared with integration
Solution:
  - Re-activate workflow
  - Update database ID if changed
  - Refresh Notion credentials
```

**Issue: Tweets marked as "Error"**
```
Symptoms: Multiple tweets with "Error" status
Diagnosis:
  - Check n8n execution log for error details
  - Common causes:
    * Tweet deleted/private
    * API rate limit hit
    * Invalid API credentials
    * Notion field mismatch
Solution:
  - Review specific error in execution log
  - Fix credential/configuration issue
  - Reset affected tweets to "Pending"
```

**Issue: Poor categorization quality**
```
Symptoms: Wrong categories, missing prompts, irrelevant tags
Diagnosis:
  - Review sample of Claude responses
  - Check if prompt is clear and specific
  - Verify temperature setting (should be 0.3)
Solution:
  - Refine Claude prompt with better examples
  - Adjust temperature if needed
  - Add more specific extraction rules
  - Manually review and create feedback loop
```

**Issue: High API costs**
```
Symptoms: Claude API costs exceeding estimates
Diagnosis:
  - Check tokens per request in Claude dashboard
  - Verify max_tokens setting (should be 500)
  - Count daily tweet processing volume
Solution:
  - Reduce max_tokens if responses are shorter
  - Consider switching to a smaller model if quality acceptable
  - Implement batch processing to reduce overhead
```

---

## Future Enhancements

### Phase 2 Features

**1. Sentiment Analysis**
```javascript
// Add sentiment field to categorization
{
  "sentiment": "positive" | "neutral" | "negative",
  "confidence": 0.95
}
```

**2. Duplicate Detection**
```javascript
// Before processing, check for similar tweets
if (similarityScore > 0.9) {
  linkToOriginal();
  skip();
}
```

**3. Thread Support**
```javascript
// Detect if tweet is part of thread
// Fetch entire thread
// Analyze as single unit
```

**4. Media Analysis**
```javascript
// Extract and analyze images in tweets
// OCR for text in images
// Image classification
```

**5. Engagement Metrics**
```javascript
// Track likes, retweets, replies
// Sort by engagement
// Identify high-value content
```

### Phase 3 Features

**1. Search Interface**
```javascript
// Build custom search UI
// Advanced filtering
// Saved searches
// Export results
```

**2. Analytics Dashboard**
```javascript
// Category distribution
// Tag frequency
// Author leaderboard
// Prompt library statistics
```

**3. Collaborative Features**
```javascript
// Multiple users
// Sharing collections
// Comments and discussions
// Rating system
```

**4. Integration Ecosystem**
```javascript
// Export to Obsidian
// Sync with Roam Research
// Slack notifications
// Email digest
```

### Technical Debt

**Current Limitations to Address:**
1. Sequential processing (implement parallel)
2. No caching (implement Redis for tweet data)
3. No deduplication (add similarity checks)
4. Limited error recovery (implement retry queue)
5. No performance monitoring (add observability)

---

## Appendix

### A. Glossary

| Term | Definition |
|------|------------|
| nano banana pro | A prompting technique/framework for AI interactions |
| n8n | Open-source workflow automation tool |
| vxtwitter | Alternative Twitter API for fetching tweet content |
| Claude Haiku | Fast, cost-effective AI model by Anthropic |
| Rich Text | Notion's formatted text data type |
| Polling | Checking for new data at regular intervals |
| Webhook | Real-time push notification of events |

### B. References

**Documentation:**
- [n8n Documentation](https://docs.n8n.io/)
- [Notion API Reference](https://developers.notion.com/)
- [Anthropic API Documentation](https://docs.anthropic.com/)
- [vxtwitter API](https://github.com/dylanpdx/BetterTwitFix)

**Related Projects:**
- Tweet archiving systems
- Content curation pipelines
- AI-powered knowledge management

### C. Change Log

| Version | Date | Changes | Author |
|---------|------|---------|--------|
| 1.0 | 2025-12-30 | Initial specification | Zamil |

### D. Contact & Support

**Project Owner:** Zamil  
**Issues:** Report via GitHub Issues (if applicable)  
**Community:** n8n Community Forum for workflow questions

---

## Summary

This specification defines a complete automated system for organizing and cataloging tweets about nano banana pro prompts. The system uses n8n for workflow orchestration, Notion for data storage, Claude AI for intelligent analysis, and vxtwitter for content extraction.

Key benefits:
- ✅ Automated categorization and tagging
- ✅ Intelligent prompt extraction
- ✅ Searchable, organized database
- ✅ Cost-effective (~$3-6/month for 3000 tweets)
- ✅ Scalable and maintainable

The system is production-ready and can process thousands of tweets with minimal manual intervention.
